#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Claude Code ä¼šè¯ç´¢å¼•å™¨

åŠŸèƒ½ï¼š
1. è§£æ JSONL ä¼šè¯æ–‡ä»¶ï¼Œæå–æ ‡é¢˜å’Œæ ‡ç­¾
2. ç”Ÿæˆ/æ›´æ–° .session-index.json ç´¢å¼•æ–‡ä»¶
3. æ”¯æŒå¢é‡æ›´æ–°ï¼Œåªå¤„ç†æ–°å¢æˆ–ä¿®æ”¹çš„æ–‡ä»¶
4. æ”¯æŒè‡ªåŠ¨å‘ç°å½“å‰é¡¹ç›®çš„ä¼šè¯ç›®å½•

ä½¿ç”¨æ–¹å¼ï¼š
    python3 session-indexer.py <session_dir> [--output json|table]
    python3 session-indexer.py --auto [--output json|table]
"""

import json
import os
import sys
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple

# é…ç½®å¸¸é‡
MAX_TITLE_LENGTH = 40  # æ ‡é¢˜æœ€å¤§é•¿åº¦
MAX_TAGS = 3  # æœ€å¤§æ ‡ç­¾æ•°é‡
INDEX_FILE_NAME = ".session-index.json"
INDEX_VERSION = "1.0.0"

# Claude ç›®å½•é…ç½®
CLAUDE_DIR = Path.home() / ".claude"
PROJECTS_DIR = CLAUDE_DIR / "projects"

# ============================================
# åˆ†å±‚ä¼˜å…ˆçº§æ ‡ç­¾è§„åˆ™ï¼ˆ4å­—ä¸­æ–‡ï¼‰
# ============================================

# ä¼˜å…ˆçº§1ï¼šä»»åŠ¡ç±»å‹ï¼ˆæœ€é‡è¦ï¼Œæè¿°ä¼šè¯åšäº†ä»€ä¹ˆï¼‰
TASK_TAGS = {
    "é”™è¯¯ä¿®å¤": ["fix", "bug", "error", "é”™è¯¯", "æŠ¥é”™", "ä¿®å¤", "è§£å†³", "å¼‚å¸¸", "å¤±è´¥"],
    "åŠŸèƒ½å¼€å‘": ["feature", "implement", "æ–°å¢", "æ·»åŠ ", "å¼€å‘", "å®ç°", "åˆ›å»º", "åŠŸèƒ½"],
    "ä»£ç é‡æ„": ["refactor", "é‡æ„", "ä¼˜åŒ–", "æ”¹è¿›", "æ•´ç†", "æ¸…ç†"],
    "é—®é¢˜è°ƒè¯•": ["debug", "è°ƒè¯•", "æ’æŸ¥", "å®šä½", "é—®é¢˜", "æ’é”™"],
    "é¡¹ç›®éƒ¨ç½²": ["deploy", "éƒ¨ç½²", "å‘å¸ƒ", "ä¸Šçº¿", "production", "çº¿ä¸Š"],
    "ç¯å¢ƒé…ç½®": ["config", "é…ç½®", "è®¾ç½®", "ç¯å¢ƒ", "env", "setting"],
    "å•å…ƒæµ‹è¯•": ["test", "æµ‹è¯•", "jest", "vitest", "å•å…ƒæµ‹è¯•", "e2e"],
    "æ–‡æ¡£ç¼–å†™": ["doc", "æ–‡æ¡£", "readme", "æ³¨é‡Š", "è¯´æ˜", "document"],
    "éœ€æ±‚åˆ†æ": ["åˆ†æ", "analysis", "ç ”ç©¶", "è°ƒç ”", "äº†è§£", "ç†è§£"],
    "æ¶æ„è®¾è®¡": ["è®¾è®¡", "design", "æ¶æ„", "æ–¹æ¡ˆ", "è§„åˆ’", "architecture"],
    "ä»£ç æäº¤": ["commit", "æäº¤", "push", "pr", "pull request", "merge"],
    "ä»£ç å®¡æŸ¥": ["review", "å®¡æŸ¥", "æ£€æŸ¥", "code review"],
}

# ä¼˜å…ˆçº§2ï¼šä¸šåŠ¡é¢†åŸŸ
DOMAIN_TAGS = {
    "æ¥å£å¼€å‘": ["api", "æ¥å£", "endpoint", "è·¯ç”±", "route", "rest"],
    "æ•°æ®å­˜å‚¨": ["database", "db", "sql", "mysql", "postgresql", "æ•°æ®åº“"],
    "ç”¨æˆ·è®¤è¯": ["auth", "login", "ç™»å½•", "è®¤è¯", "æˆæƒ", "æƒé™", "token"],
    "ç¼“å­˜ä¼˜åŒ–": ["cache", "redis", "ç¼“å­˜", "ioredis"],
    "ç•Œé¢äº¤äº’": ["ui", "ç•Œé¢", "ç»„ä»¶", "æ ·å¼", "css", "äº¤äº’", "é¡µé¢"],
    "æ€§èƒ½ä¼˜åŒ–": ["performance", "æ€§èƒ½", "ä¼˜åŒ–", "åŠ é€Ÿ", "æ…¢"],
    "é’©å­è„šæœ¬": ["hook", "é’©å­", "mcp", "pre-commit", "post-tool"],
}

# ä¼˜å…ˆçº§3ï¼šæŠ€æœ¯æ¡†æ¶ï¼ˆä»…ä½œä¸ºè¡¥å……ï¼‰
TECH_TAGS = {
    "Reactæ¡†æ¶": ["react", "jsx", "tsx", "usestate", "useeffect", "component"],
    "Vueæ¡†æ¶": ["vue", "vuex", "pinia"],
    "Nextæ¡†æ¶": ["next.js", "nextjs", "app router"],
    "Python": ["python", ".py", "pip"],
    "Javaå¼€å‘": ["java", "spring", "maven"],
    "Docker": ["docker", "container", "å®¹å™¨", "é•œåƒ"],
    "Gitæ“ä½œ": ["git", "branch", "ä»“åº“"],
}

# ============================================
# å‘½ä»¤åç§°åˆ°æ ‡é¢˜çš„æ˜ å°„è¡¨
# ============================================
COMMAND_TITLE_MAP = {
    # ä¸Šä¸‹æ–‡ç®¡ç†å‘½ä»¤
    "recover-context": "æ¢å¤ä¼šè¯ä¸Šä¸‹æ–‡",
    "load-context": "åŠ è½½ä¼šè¯ä¸Šä¸‹æ–‡",
    "save-context": "ä¿å­˜ä¼šè¯ä¸Šä¸‹æ–‡",
    "list-contexts": "åˆ—å‡ºä¼šè¯ä¸Šä¸‹æ–‡",
    "search-context": "æœç´¢ä¼šè¯ä¸Šä¸‹æ–‡",
    # é¡¹ç›®åˆ†æå‘½ä»¤
    "analysis": "é¡¹ç›®æ¶æ„åˆ†æ",
    "company": "é¡µé¢åŠŸèƒ½åˆ†æ",
    # Git ç›¸å…³å‘½ä»¤
    "git": "Git æ“ä½œ",
    "commit": "ä»£ç æäº¤",
    # ä»£ç ç›¸å…³å‘½ä»¤
    "code-explain": "ä»£ç è§£é‡Šåˆ†æ",
    "ai-review": "AI ä»£ç å®¡æŸ¥",
    "smart-debug": "æ™ºèƒ½è°ƒè¯•",
    "test-generate": "ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹",
    "doc-generate": "ç”Ÿæˆæ–‡æ¡£",
    # é¡¹ç›®è„šæ‰‹æ¶å‘½ä»¤
    "rust-project": "Rust é¡¹ç›®åˆ›å»º",
    "typescript-scaffold": "TypeScript é¡¹ç›®åˆ›å»º",
    # å…¶ä»–å‘½ä»¤
    "blog": "æŠ€æœ¯åšå®¢å†™ä½œ",
    "feature-development": "åŠŸèƒ½å¼€å‘",
    "frontend-design": "å‰ç«¯è®¾è®¡",
}

# åº”è¯¥è·³è¿‡çš„å‘½ä»¤ï¼ˆä¸ä½œä¸ºæ ‡é¢˜ï¼‰
SKIP_COMMANDS = [
    "clear",  # æ¸…ç©ºä¼šè¯å‘½ä»¤ï¼Œä¸ä»£è¡¨ä¼šè¯å†…å®¹
]

# éœ€è¦è·³è¿‡çš„æ¶ˆæ¯å‰ç¼€
SKIP_PREFIXES = [
    "<command-",
    "Caveat:",
    "<local-",
    "This session is being continued",
    "<system-reminder>",
    "```",  # ä»£ç å—å¼€å¤´
    '{"type":',  # JSON å…ƒæ•°æ®
    "âº",  # ç‰¹æ®Šæ ‡è®°
]

# ä¸é€‚åˆä½œä¸ºæ ‡é¢˜çš„æ¶ˆæ¯å‰ç¼€ï¼ˆç”¨äºæ ‡é¢˜æå–ï¼‰
SKIP_TITLE_PREFIXES = [
    # é—®å€™è¯­
    "ä½ å¥½",
    "æ‚¨å¥½",
    "hi ",
    "hello",
    # å‘½ä»¤
    "# æ¢å¤ä¼šè¯ä¸Šä¸‹æ–‡",
    "# åˆ—å‡ºä¿å­˜çš„ä¼šè¯ä¸Šä¸‹æ–‡",
    "# æœç´¢ä¼šè¯ä¸Šä¸‹æ–‡",
    "# åŠ è½½ä¼šè¯ä¸Šä¸‹æ–‡",
    "# ä¿å­˜ä¼šè¯ä¸Šä¸‹æ–‡",
    "# é¡¹ç›®æ¶æ„å¸ˆ",
    "/recover-context",
    "/save-context",
    "/list-contexts",
    "/load-context",
    "/search-context",
    "> /",  # å‘½ä»¤è¾“å‡º
    # å·¥å…·è¾“å‡ºç»“æœ
    "ğŸ“",
    "ğŸ“‹",
    "âŒ",
    "âœ…",
    "âº",
    "Exit code",
    "<tool_use_error>",
    "| åºå· |",
    "ğŸ’¡",
    # ç³»ç»Ÿæ¶ˆæ¯
    "Todos have been",
    "(eval):",
    "no matches found",
    "Shell cwd",
    "The file",
    "Here's the result",
    "File created",
    "File updated",
    "Successfully",
    # å‘½ä»¤è¡Œè¾“å‡º
    "ls:",
    "-rw",
    "-r-",
    "drw",
    "===",
    "user:",
    "File content",
    "File size",
    "null Caveat",
    "User has answered",
    "35 /Users",
    "file-history",
    "Bash(",
]

# ä¸é€‚åˆä½œä¸ºæ ‡é¢˜çš„æ¶ˆæ¯æ¨¡å¼ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
SKIP_TITLE_PATTERNS = [
    r'^\d+\s+total',  # å¦‚ "107881 total"
    r'^[\d\s]+$',  # çº¯æ•°å­—
    r'^[a-f0-9-]{36}',  # UUID
    r'^\s*$',  # ç©ºç™½
    r'^\d+\s+/Users',  # å¦‚ "35 /Users/..."
    r'^total\s+\d+',  # å¦‚ "total 123"
    r'^\d+â†’',  # å¦‚ "1â†’{"
    r'^\[\s*\{',  # JSONæ•°ç»„å¼€å¤´ "[ {"
    r'^null\s',  # null å¼€å¤´
    r'^/Users/',  # è·¯å¾„å¼€å¤´
    r'^[ğŸ“„ğŸ“ğŸ“ğŸ“‹âŒâœ…âºğŸ’¡ğŸ”]',  # emojiå¼€å¤´
]

# éœ€è¦è·³è¿‡çš„å®Œæ•´åŒ¹é…
SKIP_EXACT = [
    "",
    " ",
]


def extract_command_name(content: str) -> Optional[str]:
    """
    ä»å‘½ä»¤æ¶ˆæ¯ä¸­æå–å‘½ä»¤åç§°

    æ”¯æŒçš„æ ¼å¼ï¼š
    1. <command-name>/xxx</command-name>
    2. <command-message>xxx</command-message>
    """
    if not content:
        return None

    # åŒ¹é… <command-name>/xxx</command-name> æ ¼å¼
    match = re.search(r'<command-name>/([^<]+)</command-name>', content)
    if match:
        return match.group(1).strip()

    # åŒ¹é… <command-message>xxx</command-message> æ ¼å¼
    match = re.search(r'<command-message>([^<]+)</command-message>', content)
    if match:
        return match.group(1).strip()

    return None


def extract_title_from_prompt(content: str) -> Optional[str]:
    """
    ä»æç¤ºè¯ç¬¬ä¸€è¡Œæå–æ ‡é¢˜

    æ”¯æŒçš„æ ¼å¼ï¼š
    1. # æ ‡é¢˜å†…å®¹
    2. ## æ ‡é¢˜å†…å®¹
    """
    if not content:
        return None

    # è·å–ç¬¬ä¸€è¡Œéç©ºå†…å®¹
    lines = content.strip().split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            continue

        # åŒ¹é… Markdown æ ‡é¢˜æ ¼å¼ (# æˆ– ##)
        match = re.match(r'^#{1,2}\s+(.+)$', line)
        if match:
            title = match.group(1).strip()
            # è¿‡æ»¤æ‰å¤ªé•¿çš„æ ‡é¢˜ï¼ˆå¯èƒ½æ˜¯å®Œæ•´çš„æç¤ºè¯ï¼‰
            if len(title) <= 20:
                return title

        break  # åªæ£€æŸ¥ç¬¬ä¸€è¡Œéç©ºå†…å®¹

    return None


def get_title_from_command(command_name: str) -> Optional[str]:
    """
    æ ¹æ®å‘½ä»¤åç§°è·å–å¯¹åº”çš„æ ‡é¢˜
    """
    if not command_name:
        return None

    # æ¸…ç†å‘½ä»¤åç§°
    clean_name = command_name.lstrip('/')

    # è·³è¿‡ä¸åº”è¯¥ä½œä¸ºæ ‡é¢˜çš„å‘½ä»¤
    if clean_name in SKIP_COMMANDS:
        return None

    # ç›´æ¥ä»æ˜ å°„è¡¨æŸ¥æ‰¾
    if clean_name in COMMAND_TITLE_MAP:
        return COMMAND_TITLE_MAP[clean_name]

    # å¦‚æœæ˜ å°„è¡¨ä¸­æ²¡æœ‰ï¼Œç”Ÿæˆä¸€ä¸ªé»˜è®¤æ ‡é¢˜
    # å°† kebab-case è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
    readable = clean_name.replace('-', ' ').replace('_', ' ').title()
    if len(readable) <= 20:
        return f"{readable} å‘½ä»¤"

    return None


def extract_content_string(content) -> str:
    """
    ä»æ¶ˆæ¯å†…å®¹ä¸­æå–å­—ç¬¦ä¸²

    æ¶ˆæ¯å†…å®¹å¯èƒ½æ˜¯ï¼š
    1. å­—ç¬¦ä¸²ç±»å‹ - ç”¨æˆ·ç›´æ¥è¾“å…¥çš„æ¶ˆæ¯
    2. åˆ—è¡¨ç±»å‹ - å·¥å…·è°ƒç”¨ç»“æœï¼ˆtool_resultï¼‰
    """
    if content is None:
        return ""

    if isinstance(content, str):
        return content

    if isinstance(content, list):
        # éå†åˆ—è¡¨ï¼Œæå–æ–‡æœ¬å†…å®¹
        text_parts = []
        for item in content:
            if isinstance(item, str):
                text_parts.append(item)
            elif isinstance(item, dict):
                # å¤„ç† tool_result ç±»å‹
                if item.get('type') == 'tool_result':
                    result_content = item.get('content', '')
                    if isinstance(result_content, str):
                        text_parts.append(result_content)
                # å¤„ç† text ç±»å‹
                elif item.get('type') == 'text':
                    text_parts.append(item.get('text', ''))
        return ' '.join(text_parts)

    return str(content)


def is_valid_user_message(content: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ç”¨æˆ·æ¶ˆæ¯"""
    if not content:
        return False

    content_stripped = content.strip()

    # é•¿åº¦æ£€æŸ¥
    if len(content_stripped) < 5:
        return False

    # å®Œæ•´åŒ¹é…æ£€æŸ¥
    if content_stripped in SKIP_EXACT:
        return False

    # å‰ç¼€æ£€æŸ¥
    if any(content_stripped.startswith(prefix) for prefix in SKIP_PREFIXES):
        return False

    # è·³è¿‡çº¯å·¥å…·ç»“æœè¾“å‡ºï¼ˆé€šå¸¸ä»¥ç‰¹å®šæ ¼å¼å¼€å¤´ï¼‰
    if content_stripped.startswith('     1â†’') or content_stripped.startswith('total '):
        return False

    return True


def truncate_title(text: str, max_len: int = MAX_TITLE_LENGTH) -> str:
    """æˆªæ–­æ ‡é¢˜ï¼Œä¿ç•™å®Œæ•´è¯æ±‡"""
    # ç§»é™¤æ¢è¡Œç¬¦å’Œå¤šä½™ç©ºæ ¼
    text = re.sub(r'\s+', ' ', text.strip())

    if len(text) <= max_len:
        return text

    # æˆªæ–­å¹¶æ·»åŠ çœç•¥å·
    truncated = text[:max_len - 3].strip()
    # å°è¯•åœ¨è¯è¾¹ç•Œæˆªæ–­ï¼ˆå¯¹äºè‹±æ–‡ï¼‰
    last_space = truncated.rfind(' ')
    if last_space > max_len * 0.6:
        truncated = truncated[:last_space]

    return truncated + "..."


def is_good_title(content: str) -> bool:
    """åˆ¤æ–­æ¶ˆæ¯æ˜¯å¦é€‚åˆä½œä¸ºæ ‡é¢˜ï¼ˆæè¿°ä¼šè¯å†…å®¹çš„ä¸€å¥è¯ï¼‰"""
    if not content:
        return False

    content_stripped = content.strip()

    # è·³è¿‡ä¸é€‚åˆä½œä¸ºæ ‡é¢˜çš„æ¶ˆæ¯å‰ç¼€
    for prefix in SKIP_TITLE_PREFIXES:
        if content_stripped.lower().startswith(prefix.lower()):
            return False

    # è·³è¿‡åŒ¹é…æ­£åˆ™æ¨¡å¼çš„æ¶ˆæ¯
    for pattern in SKIP_TITLE_PATTERNS:
        if re.match(pattern, content_stripped, re.IGNORECASE):
            return False

    # è·³è¿‡å¤ªçŸ­çš„æ¶ˆæ¯ï¼ˆå¦‚"ä½ å¥½"ã€"ok"ç­‰ï¼‰
    if len(content_stripped) < 8:
        return False

    # è·³è¿‡çº¯é—®å€™è¯­
    greetings = ["ä½ å¥½", "æ‚¨å¥½", "hi", "hello", "hey", "å—¨", "ok", "å¥½çš„", "è°¢è°¢", "thanks"]
    for greeting in greetings:
        if content_stripped.lower() == greeting.lower():
            return False
        if content_stripped.lower().startswith(greeting.lower() + ",") or content_stripped.lower().startswith(greeting.lower() + "ï¼Œ"):
            # å¦‚æœé—®å€™è¯­åé¢æœ‰å®é™…å†…å®¹ï¼Œæå–åé¢çš„éƒ¨åˆ†
            return False

    # è·³è¿‡åªåŒ…å«æ¨¡å‹IDè¯¢é—®çš„æ¶ˆæ¯
    if "æ¨¡å‹" in content_stripped and "id" in content_stripped.lower() and len(content_stripped) < 20:
        return False

    return True


def extract_title_from_message(content: str) -> str:
    """ä»æ¶ˆæ¯ä¸­æå–æ ‡é¢˜ï¼Œå¤„ç†é—®å€™è¯­ç­‰æƒ…å†µ"""
    content = content.strip()

    # å¦‚æœä»¥é—®å€™è¯­å¼€å¤´ï¼Œå°è¯•æå–åé¢çš„å†…å®¹
    greeting_patterns = [
        r'^(ä½ å¥½|æ‚¨å¥½|hi|hello|hey|å—¨)[,ï¼Œã€‚.!ï¼\s]*',
    ]

    for pattern in greeting_patterns:
        match = re.match(pattern, content, re.IGNORECASE)
        if match:
            remaining = content[match.end():].strip()
            if len(remaining) >= 8:
                return truncate_title(remaining)

    return truncate_title(content)


def generate_tags(content: str, max_tags: int = MAX_TAGS) -> List[str]:
    """
    åˆ†å±‚ä¼˜å…ˆçº§æ ‡ç­¾ç”Ÿæˆ

    ä¼˜å…ˆçº§é¡ºåºï¼šä»»åŠ¡ç±»å‹ > ä¸šåŠ¡é¢†åŸŸ > æŠ€æœ¯æ¡†æ¶
    ç¡®ä¿æ ‡ç­¾èƒ½æè¿°ä¼šè¯å†…å®¹ï¼Œè€Œä¸ä»…ä»…æ˜¯æŠ€æœ¯æ ˆ
    """
    content_lower = content.lower()
    tags = []

    # ç¬¬ä¸€å±‚ï¼šä»»åŠ¡ç±»å‹ï¼ˆæœ€é‡è¦ï¼Œè‡³å°‘åŒ¹é…1-2ä¸ªï¼‰
    for tag, keywords in TASK_TAGS.items():
        if any(kw.lower() in content_lower for kw in keywords):
            if tag not in tags:
                tags.append(tag)
                if len(tags) >= 2:  # æœ€å¤š2ä¸ªä»»åŠ¡ç±»å‹
                    break

    # ç¬¬äºŒå±‚ï¼šä¸šåŠ¡é¢†åŸŸ
    if len(tags) < max_tags:
        for tag, keywords in DOMAIN_TAGS.items():
            if any(kw.lower() in content_lower for kw in keywords):
                if tag not in tags:
                    tags.append(tag)
                    if len(tags) >= max_tags:
                        break

    # ç¬¬ä¸‰å±‚ï¼šæŠ€æœ¯æ¡†æ¶ï¼ˆå¡«å……å‰©ä½™ä½ç½®ï¼‰
    if len(tags) < max_tags:
        for tag, keywords in TECH_TAGS.items():
            if any(kw.lower() in content_lower for kw in keywords):
                if tag not in tags:
                    tags.append(tag)
                    if len(tags) >= max_tags:
                        break

    return tags[:max_tags]


def parse_jsonl_file(file_path: Path) -> Tuple[Optional[str], List[str], int, Optional[str], Optional[str]]:
    """
    è§£æ JSONL æ–‡ä»¶ï¼Œæå–ä¼šè¯ä¿¡æ¯

    æ ‡é¢˜æå–ç­–ç•¥ï¼ˆç»„åˆæ–¹æ¡ˆï¼‰ï¼š
    1. ä¼˜å…ˆä»å‘½ä»¤åç§°æå–ï¼ˆå¦‚ /recover-context â†’ "æ¢å¤ä¼šè¯ä¸Šä¸‹æ–‡"ï¼‰
    2. å¦‚æœæ²¡æœ‰å‘½ä»¤ï¼Œä»æç¤ºè¯ç¬¬ä¸€è¡Œæå–ï¼ˆå¦‚ # é¡¹ç›®æ¶æ„åˆ†æï¼‰
    3. å¦‚æœéƒ½æ²¡æœ‰ï¼Œä»ç”¨æˆ·æ¶ˆæ¯ä¸­æ‰¾åˆ°å¥½çš„æ ‡é¢˜
    4. æœ€åæ‰æ˜¾ç¤º"æ— æ ‡é¢˜ä¼šè¯"

    è¿”å›: (æ ‡é¢˜, æ ‡ç­¾åˆ—è¡¨, æ¶ˆæ¯æ•°é‡, åˆ›å»ºæ—¶é—´, ä¼šè¯ID)
    """
    title = None
    command_title = None  # ä»å‘½ä»¤æå–çš„æ ‡é¢˜
    prompt_title = None   # ä»æç¤ºè¯æå–çš„æ ‡é¢˜
    all_content = []
    all_user_messages = []  # ä¿å­˜æ‰€æœ‰ç”¨æˆ·æ¶ˆæ¯ï¼Œç”¨äºæ‰¾åˆ°å¥½çš„æ ‡é¢˜
    all_raw_messages = []   # ä¿å­˜åŸå§‹æ¶ˆæ¯ï¼Œç”¨äºå‘½ä»¤å’Œæç¤ºè¯æå–
    message_count = 0
    created_at = None
    session_id = None

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f):
                if line_num > 500:  # åªè¯»å–å‰500è¡Œä»¥æé«˜æ€§èƒ½
                    break

                try:
                    data = json.loads(line.strip())
                except json.JSONDecodeError:
                    continue

                # æå–ä¼šè¯ID
                if not session_id and data.get('sessionId'):
                    session_id = data['sessionId']

                # æå–åˆ›å»ºæ—¶é—´ï¼ˆç¬¬ä¸€æ¡è®°å½•çš„æ—¶é—´æˆ³ï¼‰
                if not created_at and data.get('timestamp'):
                    created_at = data['timestamp']

                # å¤„ç†ç”¨æˆ·æ¶ˆæ¯
                if data.get('type') == 'user':
                    message = data.get('message', {})
                    raw_content = message.get('content', '')

                    # ä¿å­˜åŸå§‹æ¶ˆæ¯ç”¨äºå‘½ä»¤å’Œæç¤ºè¯æå–ï¼ˆåªä¿å­˜å‰20æ¡ï¼‰
                    if len(all_raw_messages) < 20:
                        if isinstance(raw_content, str):
                            all_raw_messages.append(raw_content)
                        elif isinstance(raw_content, list):
                            for item in raw_content:
                                if isinstance(item, dict):
                                    if item.get('type') == 'text':
                                        all_raw_messages.append(item.get('text', ''))

                    content = extract_content_string(raw_content)

                    if is_valid_user_message(content):
                        message_count += 1
                        all_content.append(content)
                        all_user_messages.append(content)

                # å¤„ç†åŠ©æ‰‹æ¶ˆæ¯ï¼ˆç”¨äºæ ‡ç­¾åˆ†æï¼‰
                elif data.get('type') == 'assistant':
                    message = data.get('message', {})
                    raw_content = message.get('content', '')
                    content = extract_content_string(raw_content)
                    if content and len(content) > 10:
                        all_content.append(content[:500])  # åªå–å‰500å­—ç¬¦

    except Exception as e:
        print(f"Error parsing {file_path}: {e}", file=sys.stderr)
        return None, [], 0, None, None

    # ============================================
    # ç»„åˆæ–¹æ¡ˆï¼šæ ‡é¢˜æå–
    # ============================================

    # æ–¹æ¡ˆ1ï¼šä»å‘½ä»¤åç§°æå–æ ‡é¢˜
    for msg in all_raw_messages[:10]:
        cmd_name = extract_command_name(msg)
        if cmd_name:
            command_title = get_title_from_command(cmd_name)
            if command_title:
                break

    # æ–¹æ¡ˆ2ï¼šä»æç¤ºè¯ç¬¬ä¸€è¡Œæå–æ ‡é¢˜
    if not command_title:
        for msg in all_raw_messages[:10]:
            prompt_title = extract_title_from_prompt(msg)
            if prompt_title:
                break

    # æ–¹æ¡ˆ3ï¼šä»ç”¨æˆ·æ¶ˆæ¯ä¸­æ‰¾åˆ°å¥½çš„æ ‡é¢˜
    user_title = None
    for msg in all_user_messages[:15]:
        if is_good_title(msg):
            user_title = extract_title_from_message(msg)
            break

    # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©æ ‡é¢˜
    if command_title:
        title = command_title
    elif prompt_title:
        title = prompt_title
    elif user_title:
        title = user_title
    else:
        title = "æ— æ ‡é¢˜ä¼šè¯"

    # ç”Ÿæˆæ ‡ç­¾ï¼ˆåŸºäºæ‰€æœ‰å†…å®¹ï¼‰
    combined_content = ' '.join(all_content[:10])  # å–å‰10æ¡æ¶ˆæ¯
    tags = generate_tags(combined_content)

    return title, tags, message_count, created_at, session_id


def get_file_info(file_path: Path) -> Dict:
    """è·å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯"""
    stat = file_path.stat()
    return {
        "size": stat.st_size,
        "mtime": datetime.fromtimestamp(stat.st_mtime).isoformat(),
    }


def load_existing_index(index_path: Path) -> Dict:
    """åŠ è½½ç°æœ‰ç´¢å¼•"""
    if index_path.exists():
        try:
            with open(index_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            pass
    return {
        "version": INDEX_VERSION,
        "updated_at": None,
        "sessions": {}
    }


def save_index(index_path: Path, index_data: Dict):
    """ä¿å­˜ç´¢å¼•æ–‡ä»¶"""
    index_data["updated_at"] = datetime.now().isoformat()
    with open(index_path, 'w', encoding='utf-8') as f:
        json.dump(index_data, f, ensure_ascii=False, indent=2)


def update_index(session_dir: Path, force: bool = False) -> Dict:
    """
    æ›´æ–°ä¼šè¯ç´¢å¼•

    Args:
        session_dir: ä¼šè¯ç›®å½•è·¯å¾„
        force: æ˜¯å¦å¼ºåˆ¶å…¨é‡æ›´æ–°

    Returns:
        æ›´æ–°åçš„ç´¢å¼•æ•°æ®
    """
    index_path = session_dir / INDEX_FILE_NAME
    index_data = load_existing_index(index_path)

    # è·å–æ‰€æœ‰ JSONL æ–‡ä»¶
    jsonl_files = list(session_dir.glob("*.jsonl"))

    # è·³è¿‡ agent-*.jsonl æ–‡ä»¶ï¼ˆå­ä»£ç†ä¼šè¯ï¼‰
    jsonl_files = [f for f in jsonl_files if not f.name.startswith("agent-")]

    # å½“å‰æ–‡ä»¶é›†åˆ
    current_files = {f.stem: f for f in jsonl_files}

    # åˆ é™¤ä¸å­˜åœ¨çš„ä¼šè¯ç´¢å¼•
    sessions_to_remove = [
        sid for sid in index_data["sessions"]
        if sid not in current_files
    ]
    for sid in sessions_to_remove:
        del index_data["sessions"][sid]

    # æ›´æ–°æˆ–æ·»åŠ ä¼šè¯ç´¢å¼•
    updated_count = 0
    for session_id, file_path in current_files.items():
        file_info = get_file_info(file_path)
        existing = index_data["sessions"].get(session_id, {})

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        needs_update = force or (
            not existing or
            existing.get("file_size") != file_info["size"] or
            existing.get("file_mtime") != file_info["mtime"]
        )

        if needs_update:
            title, tags, msg_count, created_at, _ = parse_jsonl_file(file_path)

            index_data["sessions"][session_id] = {
                "title": title,
                "tags": tags,
                "message_count": msg_count,
                "file_size": file_info["size"],
                "file_mtime": file_info["mtime"],
                "created_at": created_at,
                "last_indexed": datetime.now().isoformat(),
            }
            updated_count += 1

    # ä¿å­˜ç´¢å¼•
    if updated_count > 0 or sessions_to_remove:
        save_index(index_path, index_data)

    return index_data


def format_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.0f} KB"
    else:
        return f"{size_bytes / (1024 * 1024):.1f} MB"


def format_table_output(session_dir: Path, index_data: Dict, limit: int = 10, search: str = None) -> str:
    """æ ¼å¼åŒ–è¡¨æ ¼è¾“å‡º

    Args:
        session_dir: ä¼šè¯ç›®å½•è·¯å¾„
        index_data: ç´¢å¼•æ•°æ®
        limit: æ˜¾ç¤ºçš„æœ€å¤§è¡Œæ•°ï¼Œ0 è¡¨ç¤ºä¸é™åˆ¶
        search: æœç´¢å…³é”®è¯ï¼ˆåŒ¹é…æ ‡é¢˜ã€æ ‡ç­¾ã€æ—¥æœŸï¼‰
    """
    sessions = index_data.get("sessions", {})

    if not sessions:
        return "æš‚æ— å¯æ¢å¤çš„ä¼šè¯æ–‡ä»¶"

    # æŒ‰æ–‡ä»¶ä¿®æ”¹æ—¶é—´æ’åºï¼ˆå€’åºï¼‰
    sorted_sessions = sorted(
        sessions.items(),
        key=lambda x: x[1].get("file_mtime", ""),
        reverse=True
    )

    total_count = len(sorted_sessions)

    # åº”ç”¨æœç´¢è¿‡æ»¤
    if search:
        search_lower = search.lower()
        filtered_sessions = []
        for session_id, info in sorted_sessions:
            # æœç´¢æ ‡é¢˜
            title = (info.get("title") or "").lower()
            # æœç´¢æ ‡ç­¾
            tags = " ".join(info.get("tags", [])).lower()
            # æœç´¢æ—¥æœŸ
            mtime = info.get("file_mtime", "")

            if (search_lower in title or
                search_lower in tags or
                search_lower in mtime or
                search_lower in session_id.lower()):
                filtered_sessions.append((session_id, info))

        sorted_sessions = filtered_sessions

    # æ„å»ºè¡¨æ ¼
    lines = []
    lines.append(f"ğŸ“ ä¼šè¯ç›®å½•: {session_dir}")
    lines.append("")

    filtered_count = len(sorted_sessions)

    # æœç´¢æ¨¡å¼ä¸‹çš„æ ‡é¢˜
    if search:
        if filtered_count == 0:
            lines.append(f"ğŸ” æœç´¢ \"{search}\" æ— ç»“æœï¼ˆå…± {total_count} ä¸ªä¼šè¯ï¼‰")
            lines.append("")
            lines.append("ğŸ’¡ å°è¯•å…¶ä»–å…³é”®è¯ï¼Œæˆ–ä½¿ç”¨ `--limit 0` æŸ¥çœ‹å…¨éƒ¨ä¼šè¯")
            return "\n".join(lines)
        else:
            lines.append(f"ğŸ” æœç´¢ \"{search}\" æ‰¾åˆ° {filtered_count} ä¸ªåŒ¹é…ï¼ˆå…± {total_count} ä¸ªä¼šè¯ï¼‰ï¼š")
    else:
        # åº”ç”¨ limit
        if limit > 0 and filtered_count > limit:
            sorted_sessions = sorted_sessions[:limit]
            lines.append(f"ğŸ“‹ å¯æ¢å¤çš„ä¼šè¯æ–‡ä»¶ï¼ˆæŒ‰æ—¶é—´å€’åºï¼Œæ˜¾ç¤ºå‰ {limit} ä¸ªï¼Œå…± {total_count} ä¸ªï¼‰ï¼š")
        else:
            lines.append(f"ğŸ“‹ å¯æ¢å¤çš„ä¼šè¯æ–‡ä»¶ï¼ˆæŒ‰æ—¶é—´å€’åºï¼Œå…± {total_count} ä¸ªï¼‰ï¼š")

    lines.append("")
    lines.append("| åºå· | æ–‡ä»¶å                               | ä¿®æ”¹æ—¶é—´         | ä¸»è¦å†…å®¹                          | æ ‡ç­¾                              | å¤§å°     |")
    lines.append("|------|--------------------------------------|------------------|----------------------------------|-----------------------------------|----------|")

    for idx, (session_id, info) in enumerate(sorted_sessions, 1):
        # è§£æä¿®æ”¹æ—¶é—´
        mtime = info.get("file_mtime", "")
        if mtime:
            try:
                dt = datetime.fromisoformat(mtime)
                mtime_str = dt.strftime("%Y-%m-%d %H:%M")
            except:
                mtime_str = mtime[:16]
        else:
            mtime_str = "æœªçŸ¥"

        # æ ‡é¢˜ï¼ˆé™åˆ¶é•¿åº¦ï¼‰
        title = info.get("title") or "æ— æ ‡é¢˜"
        if len(title) > 32:
            title = title[:29] + "..."

        # æ ‡ç­¾ï¼ˆå®Œæ•´æ˜¾ç¤ºï¼Œä¸æˆªæ–­ï¼‰
        tags = info.get("tags", [])
        tags_str = " ".join([f"#{t}" for t in tags]) if tags else "-"

        # å¤§å°
        size = info.get("file_size", 0)
        size_str = format_size(size)
        # å¤§æ–‡ä»¶æ ‡è®°
        if size > 1024 * 1024:  # > 1MB
            size_str += " â­"

        # æ–‡ä»¶åï¼ˆsession_id + .jsonlï¼‰
        filename = f"{session_id}.jsonl"

        # æ ¼å¼åŒ–è¡Œï¼ˆæ ‡ç­¾åˆ—å®½åº¦å¢åŠ åˆ°35å­—ç¬¦ï¼‰
        lines.append(
            f"| [{idx:2d}] | {filename:36s} | {mtime_str:16s} | {title:32s} | {tags_str:35s} | {size_str:8s} |"
        )

    lines.append("")
    lines.append("---")
    lines.append("ğŸ’¡ ä½¿ç”¨ `/recover-context [åºå·]` æ¢å¤æŒ‡å®šä¼šè¯ï¼ˆå¦‚ `/recover-context 3`ï¼‰")
    lines.append("ğŸ’¡ ä½¿ç”¨ `/recover-context latest` æ¢å¤æœ€æ–°ä¼šè¯")
    if not search:
        if limit > 0 and total_count > limit:
            lines.append(f"ğŸ’¡ è¾“å…¥ `more` æ˜¾ç¤ºæ›´å¤šï¼Œæˆ– `more 50` æ˜¾ç¤ºå‰ 50 ä¸ª")
        lines.append(f"ğŸ’¡ è¾“å…¥ `search å…³é”®è¯` æœç´¢ä¼šè¯ï¼ˆå¦‚ `search é”™è¯¯å¤„ç†`ï¼‰")

    return "\n".join(lines)


def format_json_output(index_data: Dict) -> str:
    """æ ¼å¼åŒ– JSON è¾“å‡º"""
    return json.dumps(index_data, ensure_ascii=False, indent=2)


def auto_discover_session_dir() -> Optional[Path]:
    """
    è‡ªåŠ¨å‘ç°å½“å‰é¡¹ç›®çš„ä¼šè¯ç›®å½•

    æ ¹æ®å½“å‰å·¥ä½œç›®å½•ï¼Œè‡ªåŠ¨æŸ¥æ‰¾å¯¹åº”çš„ Claude Code ä¼šè¯ç›®å½•
    """
    cwd = os.getcwd()

    # Claude Code ä½¿ç”¨ - æ›¿æ¢ / ä½œä¸ºç›®å½•å
    encoded_path = cwd.replace("/", "-")

    # å°è¯•ä¸¤ç§å¯èƒ½çš„è·¯å¾„æ ¼å¼
    possible_paths = [
        PROJECTS_DIR / encoded_path,           # æ ‡å‡†æ ¼å¼
        PROJECTS_DIR / f"-{encoded_path}",     # å¸¦å‰ç¼€æ ¼å¼ï¼ˆæŸäº›ç³»ç»Ÿï¼‰
    ]

    for session_dir in possible_paths:
        if session_dir.exists():
            # éªŒè¯ç›®å½•ä¸­æœ‰ JSONL æ–‡ä»¶
            jsonl_files = list(session_dir.glob("*.jsonl"))
            if jsonl_files:
                return session_dir

    return None


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="Claude Code ä¼šè¯ç´¢å¼•å™¨")
    parser.add_argument("session_dir", nargs='?', default=None,
                        help="ä¼šè¯ç›®å½•è·¯å¾„ï¼ˆå¯é€‰ï¼Œä½¿ç”¨ --auto æ—¶è‡ªåŠ¨å‘ç°ï¼‰")
    parser.add_argument("--auto", "-a", action="store_true",
                        help="è‡ªåŠ¨å‘ç°å½“å‰é¡¹ç›®çš„ä¼šè¯ç›®å½•")
    parser.add_argument("--output", "-o", choices=["json", "table"], default="table",
                        help="è¾“å‡ºæ ¼å¼ (default: table)")
    parser.add_argument("--force", "-f", action="store_true",
                        help="å¼ºåˆ¶å…¨é‡æ›´æ–°ç´¢å¼•")
    parser.add_argument("--limit", "-l", type=int, default=10,
                        help="è¡¨æ ¼æ˜¾ç¤ºçš„æœ€å¤§è¡Œæ•° (default: 10, 0=ä¸é™åˆ¶)")
    parser.add_argument("--search", "-s", type=str, default=None,
                        help="æœç´¢å…³é”®è¯ï¼ˆåŒ¹é…æ ‡é¢˜ã€æ ‡ç­¾ã€æ—¥æœŸï¼‰")

    args = parser.parse_args()

    # ç¡®å®šä¼šè¯ç›®å½•
    if args.auto:
        session_dir = auto_discover_session_dir()
        if not session_dir:
            print("âŒ æœªæ‰¾åˆ°å½“å‰é¡¹ç›®çš„ä¼šè¯ç›®å½•", file=sys.stderr)
            print(f"æç¤º: è¯·ç¡®è®¤åœ¨é¡¹ç›®ç›®å½•ä¸­è¿è¡Œï¼Œæˆ–æ‰‹åŠ¨æŒ‡å®šä¼šè¯ç›®å½•è·¯å¾„", file=sys.stderr)
            sys.exit(1)
    elif args.session_dir:
        session_dir = Path(args.session_dir)
    else:
        # æ—¢æ²¡æœ‰ --auto ä¹Ÿæ²¡æœ‰æŒ‡å®šç›®å½•ï¼Œæ˜¾ç¤ºå¸®åŠ©
        parser.print_help()
        print("\nç¤ºä¾‹ç”¨æ³•:")
        print("  python3 session-indexer.py --auto           # è‡ªåŠ¨å‘ç°å½“å‰é¡¹ç›®ä¼šè¯")
        print("  python3 session-indexer.py /path/to/dir     # æŒ‡å®šä¼šè¯ç›®å½•")
        sys.exit(1)

    if not session_dir.exists():
        print(f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨ - {session_dir}", file=sys.stderr)
        sys.exit(1)

    # æ›´æ–°ç´¢å¼•
    index_data = update_index(session_dir, force=args.force)

    # è¾“å‡ºç»“æœ
    if args.output == "json":
        print(format_json_output(index_data))
    else:
        print(format_table_output(session_dir, index_data, limit=args.limit, search=args.search))


if __name__ == "__main__":
    main()
